{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the same model as that present in the Capstone Project.ipynb.\n",
    "The only difference that lies here is that I have used tensorflow.summary module in order to store the values of all the tensors that are present and have been used throughout the model, so that I can get visualizations for the project model using tensorflow's tensorboard module.\n",
    "For the documetation please refer to the Capstone Project.ipynb file. The codes are 100% the same except for the usage of tf.summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1427\n",
      "1427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "DATA_DIR = \"E:\\\\train\"\n",
    "names=[]\n",
    "i=0\n",
    "for root, dirs, files in os.walk(DATA_DIR,topdown=False):\n",
    "    for name in files:\n",
    "        names.append(name.replace('.jpeg',''))\n",
    "print(len(names))\n",
    "df_Org=pd.read_csv(\"E:/trainLabels.csv/trainLabels.csv\")\n",
    "sf=df_Org.values.tolist()\n",
    "\n",
    "df=[]\n",
    "for name in names:\n",
    "    for i in range (0,len(sf)):\n",
    "        if(sf[i][0]==name):\n",
    "            df.append(sf[i])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1426, 340, 512, 3)\n",
      "(1426, 1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "x=[]\n",
    "y=[]\n",
    "for i in range (0,len(df)-1):\n",
    "    img = cv2.imread(\"E://train//\"+df[i][0]+\".jpeg\")\n",
    "    img = cv2.resize(img,(512,340))\n",
    "    img = np.array(img).reshape((340,512,3))\n",
    "    x.append(img)\n",
    "    y.append(df[i][1])\n",
    "    i+=1\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "y=np.array(y).reshape(len(y),1)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 340, 512, 3)\n",
      "(10, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "x_train, x_test, y_train, y_test = tts(x, y, test_size=0.2987, random_state=42)\n",
    "X_train=np.split(x_train,10)\n",
    "y_train=np.split(y_train,10)\n",
    "print(np.array(X_train).shape)\n",
    "print(np.array(y_train).shape)\n",
    "\n",
    "X_test=x_test[:400]\n",
    "Y_test=y_test[:400]\n",
    "x_test=np.split(X_test,4)\n",
    "y_test=np.split(Y_test,4)\n",
    "\n",
    "def one_hot_encode(x):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    enc=OneHotEncoder(n_values=5)\n",
    "    ohc_labels=enc.fit_transform(np.array(x).reshape(-1,1)).toarray()\n",
    "    return ohc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda3\\envs\\testenv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(\"float\", shape=[None,340,512,3], name='x')\n",
    "    y = tf.placeholder(\"float\", shape=[None,5], name='y')\n",
    "\n",
    "with tf.name_scope('dropout'):\n",
    "    keep_probs = tf.placeholder(tf.float32, name='keep_probs')\n",
    "    tf.summary.scalar('dropout_keep_probability', keep_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(inp_lyr,ofilters,kernel,stride):\n",
    "    conv2d_lyr=tf.layers.conv2d(inputs=inp_lyr,\n",
    "                               filters=ofilters,\n",
    "                               kernel_size=kernel,\n",
    "                               strides=stride,\n",
    "                               padding=\"same\",\n",
    "                               activation=tf.nn.relu,\n",
    "                               )\n",
    "    return conv2d_lyr\n",
    "\n",
    "def maxpool2d(inp_lyr,pool,stride):\n",
    "    maxp2d=tf.layers.max_pooling2d(inputs=inp_lyr,\n",
    "                                 pool_size=pool,\n",
    "                                 strides=stride,\n",
    "                                 padding=\"same\")\n",
    "    return maxp2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    img_inp=tf.reshape(x,[-1,340,512,3])\n",
    "    layer=conv2d(img_inp,32,[7,7],[2,2])\n",
    "    layer=maxpool2d(layer,[5,5],[2,2])\n",
    "    \n",
    "    layer=conv2d(layer,32,[5,5],[1,1])\n",
    "    layer=conv2d(layer,64,[3,3],[1,1])\n",
    "    layer=maxpool2d(layer,[3,3],[2,2])\n",
    "    \n",
    "    layer=conv2d(layer,64,[3,3],[1,1])\n",
    "    layer=conv2d(layer,128,[3,3],[1,1])\n",
    "    layer=conv2d(layer,256,[3,3],[1,1])\n",
    "    layer=maxpool2d(layer,[3,3],[2,2])\n",
    "    \n",
    "    layer=tf.layers.dropout(layer,0.4)\n",
    "    \n",
    "    layer=tf.layers.flatten(layer)\n",
    "    \n",
    "    layer=tf.layers.dense(layer,256)\n",
    "    layer=tf.layers.dense(layer,512)\n",
    "    layer=tf.layers.dense(layer,1024)\n",
    "    \n",
    "    layer=tf.layers.dense(layer,5)\n",
    "    \n",
    "    layer=tf.nn.softmax(layer)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for epoch in range(15):\n",
    "        for i in range (0,10):\n",
    "            x_img=X_train[i]\n",
    "            y_img=one_hot_encode(y_train[i])\n",
    "            train_summary, train_acc = sess.run([merged, acc], feed_dict={x:x_img,\n",
    "                                                                                y: y_img,\n",
    "                                                                                keep_probs: 1.0})\n",
    "            train_writer.add_summary(train_summary, epoch+1+(i+1)/100)\n",
    "            print('Epoch: {} Batch: {} Accuracy = {:.6f}'.format(epoch+1, i+1, train_acc))\n",
    "            sess.run(epoch_batch,feed_dict={x: x_img, y: y_img, keep_probs: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'acc:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_mod=model()\n",
    "cnn_mod=tf.identity(cnn_mod, name='model')\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy=-tf.reduce_sum(y*tf.log(cnn_mod))\n",
    "tf.summary.scalar('cross_entropy',cross_entropy)\n",
    "\n",
    "with tf.name_scope('training'):\n",
    "    epoch_batch=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_preds'):\n",
    "        corr_pred=tf.equal(tf.argmax(cnn_mod, 1), tf.argmax(y, 1))\n",
    "        \n",
    "    with tf.name_scope('accuracy'):\n",
    "        acc=tf.reduce_mean(tf.cast(corr_pred, tf.float32), name='acc')\n",
    "tf.summary.scalar('acc',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1 Accuracy = 0.050000\n",
      "Epoch: 1 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 1 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 1 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 1 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 1 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 1 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 1 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 1 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 1 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 2 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 2 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 2 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 2 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 2 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 2 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 2 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 2 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 2 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 2 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 3 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 3 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 3 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 3 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 3 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 3 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 3 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 3 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 3 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 3 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 4 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 4 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 4 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 4 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 4 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 4 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 4 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 4 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 4 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 4 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 5 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 5 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 5 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 5 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 5 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 5 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 5 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 5 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 5 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 5 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 6 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 6 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 6 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 6 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 6 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 6 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 6 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 6 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 6 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 6 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 7 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 7 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 7 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 7 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 7 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 7 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 7 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 7 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 7 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 7 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 8 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 8 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 8 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 8 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 8 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 8 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 8 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 8 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 8 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 8 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 9 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 9 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 9 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 9 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 9 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 9 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 9 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 9 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 9 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 9 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 10 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 10 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 10 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 10 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 10 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 10 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 10 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 10 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 10 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 10 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 11 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 11 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 11 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 11 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 11 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 11 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 11 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 11 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 11 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 11 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 12 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 12 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 12 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 12 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 12 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 12 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 12 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 12 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 12 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 12 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 13 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 13 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 13 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 13 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 13 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 13 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 13 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 13 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 13 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 13 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 14 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 14 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 14 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 14 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 14 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 14 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 14 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 14 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 14 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 14 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 15 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 15 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 15 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 15 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 15 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 15 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 15 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 15 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 15 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 15 Batch: 10 Accuracy = 0.770000\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())  \n",
    "merged=tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('F:/Work/Summaries' + '/train', sess.graph)\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path='F:/Work/Summaries/capstone'\n",
    "train_writer.close()\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Magenta",
   "language": "python",
   "name": "magenta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
