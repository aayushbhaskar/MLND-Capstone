{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1427\n"
     ]
    }
   ],
   "source": [
    "#code to get names of the images in dataset so that lables can be assigned\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#defining the address of the dataset\n",
    "DATA_DIR = \"E:\\\\train\"\n",
    "names=[]\n",
    "i=0\n",
    "for root, dirs, files in os.walk(DATA_DIR,topdown=False):\n",
    "    for name in files:\n",
    "        names.append(name.replace('.jpeg',''))\n",
    "        #print(names[i])\n",
    "        #i+=1\n",
    "print(len(names))\n",
    "df_Org=pd.read_csv(\"E:\\\\trainLabels.csv\\\\trainLabels.csv\")\n",
    "sf=df_Org.values.tolist()\n",
    "#print(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1427\n"
     ]
    }
   ],
   "source": [
    "#extracting the labels for all the images in the dataset\n",
    "df=[]\n",
    "for name in names:\n",
    "    for i in range (0,len(sf)):\n",
    "        if(sf[i][0]==name):\n",
    "            df.append(sf[i])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1426, 340, 512, 3)\n",
      "(1426, 1)\n"
     ]
    }
   ],
   "source": [
    "#getting all the images and creating the dataset arrays x and y\n",
    "import cv2\n",
    "import numpy as np\n",
    "x=[]\n",
    "y=[]\n",
    "for i in range (0,len(df)-1):\n",
    "    #raeding in the image\n",
    "    img = cv2.imread(\"E://train//\"+df[i][0]+\".jpeg\")\n",
    "    #resizing the image\n",
    "    img = cv2.resize(img,(512,340))\n",
    "    #changing the array to a numpy n-dimensional array and setting its shape\n",
    "    img = np.array(img).reshape((340,512,3))\n",
    "    #adding the image to the training data array\n",
    "    x.append(img)\n",
    "    #adding the labels\n",
    "    y.append(df[i][1])\n",
    "    i+=1\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "y=np.array(y).reshape(len(y),1)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 340, 512, 3)\n",
      "(10, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "#splitting up the data into training and testing data\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "x_train, x_test, y_train, y_test = tts(x, y, test_size=0.2987, random_state=42)\n",
    "X_train=np.split(x_train,10)\n",
    "y_train=np.split(y_train,10)\n",
    "print(np.array(X_train).shape)\n",
    "print(np.array(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizaruion function for the dataset\n",
    "def normalize(x):\n",
    "    max_x,min_x=x.max(),x.min()\n",
    "    norm_x=np.zeros(tuple(x.shape))\n",
    "    norm_img=x.shape[0]\n",
    "    for nr in range(norm_img):\n",
    "        norm_x[nr,...]=(x[nr,...]-float(min_x))/(float(max_x-min_x))\n",
    "    return norm_x\n",
    "\n",
    "#function for one hot encoding the labels\n",
    "def one_hot_encode(x):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    enc=OneHotEncoder(n_values=5)\n",
    "    ohc_labels=enc.fit_transform(np.array(x).reshape(-1,1)).toarray()\n",
    "    return ohc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\anaconda3\\envs\\testenv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#declaring tensorflow global variables\n",
    "x = tf.placeholder(\"float\", shape=[None,340,512,3], name='x')\n",
    "y = tf.placeholder(\"float\", shape=[None,5], name='y')\n",
    "keep_probs = tf.placeholder(\"float\", name='keep_probs')\n",
    "\n",
    "#defining the convolution 2d layer\n",
    "def conv2d(inp_lyr,ofilters,kernel,stride):\n",
    "    conv2d_lyr=tf.layers.conv2d(inputs=inp_lyr,\n",
    "                               filters=ofilters,\n",
    "                               kernel_size=kernel,\n",
    "                               strides=stride,\n",
    "                               padding=\"same\",\n",
    "                               activation=tf.nn.relu,\n",
    "                               )\n",
    "    return conv2d_lyr\n",
    "\n",
    "#defing the maxpool 2d layer\n",
    "def maxpool2d(inp_lyr,pool,stride):\n",
    "    maxp2d=tf.layers.max_pooling2d(inputs=inp_lyr,\n",
    "                                 pool_size=pool,\n",
    "                                 strides=stride,\n",
    "                                 padding=\"same\")\n",
    "    return maxp2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    #getting the input\n",
    "    img_inp=tf.reshape(x,[-1,340,512,3])\n",
    "    #one convolution and one maxpool layer\n",
    "    layer=conv2d(img_inp,32,[7,7],[2,2])\n",
    "    layer=maxpool2d(layer,[5,5],[2,2])\n",
    "    \n",
    "    #two convolution and one maxpool layer\n",
    "    layer=conv2d(layer,32,[5,5],[1,1])\n",
    "    layer=conv2d(layer,64,[3,3],[1,1])\n",
    "    layer=maxpool2d(layer,[3,3],[2,2])\n",
    "    \n",
    "    #three convolution and one maxpool layer\n",
    "    layer=conv2d(layer,64,[3,3],[1,1])\n",
    "    layer=conv2d(layer,128,[3,3],[1,1])\n",
    "    layer=conv2d(layer,256,[3,3],[1,1])\n",
    "    layer=maxpool2d(layer,[3,3],[2,2])\n",
    "    \n",
    "    #dropout layer\n",
    "    layer=tf.layers.dropout(layer,0.4)\n",
    "    \n",
    "    #flattening layer\n",
    "    layer=tf.layers.flatten(layer)\n",
    "    \n",
    "    #dense (fully connected) layers\n",
    "    layer=tf.layers.dense(layer,256)\n",
    "    layer=tf.layers.dense(layer,512)\n",
    "    layer=tf.layers.dense(layer,1024)\n",
    "    \n",
    "    layer=tf.layers.dense(layer,5)\n",
    "    \n",
    "    #activation layer\n",
    "    layer=tf.nn.softmax(layer)\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the global training variables\n",
    "cnn_mod=model()\n",
    "cnn_mod=tf.identity(cnn_mod, name='model')\n",
    "cross_entropy=-tf.reduce_sum(y*tf.log(cnn_mod))\n",
    "epoch_batch=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "corr_pred=tf.equal(tf.argmax(cnn_mod, 1), tf.argmax(y, 1))\n",
    "acc=tf.reduce_mean(tf.cast(corr_pred, tf.float32), name='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function which will be called for training the model\n",
    "def train_model():\n",
    "    for epoch in range(15):\n",
    "        for i in range (0,10):\n",
    "            x_img=normalize(X_train[i])\n",
    "            y_img=one_hot_encode(y_train[i])\n",
    "            tr_acc=sess.run(acc,feed_dict={x: x_img, y: y_img, keep_probs: 1.0})\n",
    "            print('Epoch: {} Batch: {} Accuracy = {:.6f}'.format(epoch+1, i+1, tr_acc))\n",
    "            sess.run(epoch_batch,feed_dict={x: x_img, y: y_img, keep_probs: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Batch: 1 Accuracy = 0.060000\n",
      "Epoch: 1 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 1 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 1 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 1 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 1 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 1 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 1 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 1 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 1 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 2 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 2 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 2 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 2 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 2 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 2 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 2 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 2 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 2 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 2 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 3 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 3 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 3 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 3 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 3 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 3 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 3 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 3 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 3 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 3 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 4 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 4 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 4 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 4 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 4 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 4 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 4 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 4 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 4 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 4 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 5 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 5 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 5 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 5 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 5 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 5 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 5 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 5 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 5 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 5 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 6 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 6 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 6 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 6 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 6 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 6 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 6 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 6 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 6 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 6 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 7 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 7 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 7 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 7 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 7 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 7 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 7 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 7 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 7 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 7 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 8 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 8 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 8 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 8 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 8 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 8 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 8 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 8 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 8 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 8 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 9 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 9 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 9 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 9 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 9 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 9 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 9 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 9 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 9 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 9 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 10 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 10 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 10 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 10 Batch: 4 Accuracy = 0.740000\n",
      "Epoch: 10 Batch: 5 Accuracy = 0.730000\n",
      "Epoch: 10 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 10 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 10 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 10 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 10 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 11 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 11 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 11 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 11 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 11 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 11 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 11 Batch: 7 Accuracy = 0.670000\n",
      "Epoch: 11 Batch: 8 Accuracy = 0.780000\n",
      "Epoch: 11 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 11 Batch: 10 Accuracy = 0.790000\n",
      "Epoch: 12 Batch: 1 Accuracy = 0.710000\n",
      "Epoch: 12 Batch: 2 Accuracy = 0.740000\n",
      "Epoch: 12 Batch: 3 Accuracy = 0.700000\n",
      "Epoch: 12 Batch: 4 Accuracy = 0.760000\n",
      "Epoch: 12 Batch: 5 Accuracy = 0.720000\n",
      "Epoch: 12 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 12 Batch: 7 Accuracy = 0.680000\n",
      "Epoch: 12 Batch: 8 Accuracy = 0.770000\n",
      "Epoch: 12 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 12 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 13 Batch: 1 Accuracy = 0.700000\n",
      "Epoch: 13 Batch: 2 Accuracy = 0.760000\n",
      "Epoch: 13 Batch: 3 Accuracy = 0.710000\n",
      "Epoch: 13 Batch: 4 Accuracy = 0.740000\n",
      "Epoch: 13 Batch: 5 Accuracy = 0.730000\n",
      "Epoch: 13 Batch: 6 Accuracy = 0.690000\n",
      "Epoch: 13 Batch: 7 Accuracy = 0.680000\n",
      "Epoch: 13 Batch: 8 Accuracy = 0.790000\n",
      "Epoch: 13 Batch: 9 Accuracy = 0.720000\n",
      "Epoch: 13 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 14 Batch: 1 Accuracy = 0.700000\n",
      "Epoch: 14 Batch: 2 Accuracy = 0.760000\n",
      "Epoch: 14 Batch: 3 Accuracy = 0.720000\n",
      "Epoch: 14 Batch: 4 Accuracy = 0.770000\n",
      "Epoch: 14 Batch: 5 Accuracy = 0.730000\n",
      "Epoch: 14 Batch: 6 Accuracy = 0.700000\n",
      "Epoch: 14 Batch: 7 Accuracy = 0.700000\n",
      "Epoch: 14 Batch: 8 Accuracy = 0.830000\n",
      "Epoch: 14 Batch: 9 Accuracy = 0.710000\n",
      "Epoch: 14 Batch: 10 Accuracy = 0.770000\n",
      "Epoch: 15 Batch: 1 Accuracy = 0.700000\n",
      "Epoch: 15 Batch: 2 Accuracy = 0.770000\n",
      "Epoch: 15 Batch: 3 Accuracy = 0.730000\n",
      "Epoch: 15 Batch: 4 Accuracy = 0.770000\n",
      "Epoch: 15 Batch: 5 Accuracy = 0.740000\n",
      "Epoch: 15 Batch: 6 Accuracy = 0.710000\n",
      "Epoch: 15 Batch: 7 Accuracy = 0.710000\n",
      "Epoch: 15 Batch: 8 Accuracy = 0.810000\n",
      "Epoch: 15 Batch: 9 Accuracy = 0.720000\n",
      "Epoch: 15 Batch: 10 Accuracy = 0.770000\n"
     ]
    }
   ],
   "source": [
    "#declaring a session, initializing it and training the model\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())    \n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model so that it can be read back later on\n",
    "save_model_path='F:/Work/capstone'\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the test data\n",
    "X_test=x_test[:400]\n",
    "Y_test=y_test[:400]\n",
    "x_test=np.split(X_test,4)\n",
    "y_test=np.split(Y_test,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from F:/Work/capstone\n",
      "Testing Accuracy: 0.6799999922513962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining the function that will test the model on unknown data\n",
    "def test_model():\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_probs:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('acc:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for i in range(0,4):\n",
    "            x_test_img=normalize(x_test[i])\n",
    "            y_test_img=one_hot_encode(y_test[i])\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: x_test_img, loaded_y: y_test_img, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Magenta",
   "language": "python",
   "name": "magenta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
